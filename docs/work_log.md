# 工作记录

## 2025-03-15

### 完成工作

1. **修复了测试脚本中的边处理问题**
   - 发现数据库中的边类型与之前指定的不匹配
   - 正确的边类型为：`DC_TO_TENANT`, `TENANT_TO_NE`, `NE_TO_VM`, `VM_TO_HOST`, `HOST_TO_HA`, `HA_TO_TRU`
   - 修改了测试脚本，使用数据库中实际存在的边类型

2. **修复了数据加载器中的边特征处理问题**
   - 解决了边特征向量维度不一致的问题
   - 实现了特征向量的零填充，确保所有特征向量具有相同的维度

3. **添加了全面覆盖测试功能**
   - 实现了节点类型、边类型、动态属性和复杂链路组合的全面覆盖测试
   - 添加了统计信息收集功能，包括节点类型统计、边类型统计、动态属性统计等

4. **添加了复杂查询样本生成功能**
   - 实现了复杂路径查询样本的生成
   - 生成的查询样本可以用于测试图谱问答系统

5. **添加了统计信息查询样本生成功能**
   - 实现了资源使用情况查询样本的生成
   - 实现了异常状态传播路径查询样本的生成
   - 实现了层级统计信息查询样本的生成

### 讨论记录

1. **图-文对样本的准确性问题**
   - 讨论了生成的图-文对样本中答案部分的准确性问题
   - 分析了RAG系统的设计文档，理解了双编码器的目的是检索而非生成
   - 确认了系统的完整流程：使用双编码器找到相关图结构，生成Cypher查询获取准确数据，使用LLM生成最终答案
   - 结论：当前生成的样本中的随机数值不会影响系统的训练效果，因为训练的目标是让文本查询和相关图结构的表示在语义空间中接近

### 下一步计划

1. **完善统计信息查询样本生成**
   - 考虑添加更多类型的统计信息查询
   - 优化查询样本的多样性和覆盖面

2. **实现LLM集成**
   - 设计提示工程策略
   - 实现查询意图识别
   - 开发Cypher查询生成器

3. **开发Agent系统**
   - 设计Agent架构
   - 实现任务规划
   - 开发工具调用接口
   - 集成对话管理 

## 2025-03-22

### 完成工作

1. **实现了动态异构图编码器**
   - 完成了节点级注意力层（NodeLevelAttention）的实现
   - 完成了边级注意力层（EdgeLevelAttention）的实现
   - 完成了时间序列编码器（TimeSeriesEncoder）的实现
   - 完成了时间级注意力层（TemporalLevelAttention）的实现
   - 完成了层级感知模块（HierarchicalAwarenessModule）的实现
   - 完成了完整的动态异构图编码器（DynamicHeterogeneousGraphEncoder）的实现

2. **解决了关键技术问题**
   - 修复了节点级注意力层中的维度不匹配问题
   - 优化了不使用边特征时的处理逻辑
   - 实现了灵活的特征融合策略，支持多种输入组合
   - 添加了残差连接和层归一化，提高模型稳定性

3. **完成了全面的测试**
   - 实现了所有组件的单元测试
   - 实现了完整编码器的集成测试
   - 验证了不同输入条件下的正确性
   - 所有测试均通过，确认了编码器的鲁棒性和灵活性

4. **开发了测试结果可视化工具**
   - 实现了测试结果的JSON格式保存
   - 开发了测试状态可视化功能
   - 实现了子测试结果可视化
   - 实现了参数比较可视化
   - 优化了可视化工具的错误处理和数据验证

5. **更新了相关文档**
   - 更新了图编码器设计文档，添加了实现状态和测试结果
   - 更新了项目进度报告，将图编码器从"即将开始的工作"移到"当前完成的工作"
   - 添加了详细的组件描述和测试结果说明

### 讨论记录

1. **图编码器架构优化**
   - 讨论了原始设计与实际实现的差异
   - 分析了不同注意力机制的优缺点
   - 确认了当前实现的架构能够满足项目需求
   - 讨论了未来可能的优化方向

2. **测试策略**
   - 讨论了测试覆盖率和测试用例设计
   - 分析了不同输入组合的测试重要性
   - 确认了测试结果的可视化方式
   - 讨论了自动化测试的实现方案

### 下一步计划

1. **实现文本编码器**
   - 基于预训练的中文BERT模型
   - 实现文本特征提取
   - 支持多种池化策略
   - 添加特征投影层

2. **实现双通道编码器集成**
   - 实现文本和图特征对齐
   - 设计对比学习损失函数
   - 实现联合训练流程
   - 优化特征空间分布

## 2025-03-23

### 完成工作

1. **优化了双通道编码器架构**
   - 移除了旧版基于GAT的简单图编码器（graph_encoder.py）
   - 更新了双通道编码器（dual_encoder.py）以使用新的动态异构图编码器
   - 调整了接口参数以支持更复杂的图结构和特征
   - 保持了与原有接口的兼容性，同时支持新的特性

2. **更新了接口设计**
   - 修改了encode_graph方法的参数，支持边类型字典和时间序列特征
   - 更新了forward方法的参数，支持层级信息和时间序列特征
   - 调整了图编码器的初始化参数，添加了节点类型、边类型、时间序列维度等参数
   - 确保了接口的一致性和可扩展性

3. **更新了相关文档**
   - 更新了项目进度报告，添加了双通道编码器集成的内容
   - 更新了工作日志，记录了架构优化的详细信息
   - 调整了后续工作计划和时间线

### 讨论记录

1. **架构优化的必要性**
   - 讨论了移除旧版图编码器的原因和好处
   - 分析了新旧编码器的性能和功能差异
   - 确认了新架构能够更好地支持项目需求
   - 讨论了接口变更对现有代码的影响

2. **接口设计的考量**
   - 讨论了如何保持接口的一致性和可扩展性
   - 分析了不同参数组合的处理方式
   - 确认了默认参数的设置原则
   - 讨论了接口文档的更新方式

### 下一步计划

1. **实现文本编码器**
   - 基于预训练的中文BERT模型
   - 实现文本特征提取
   - 支持多种池化策略
   - 添加特征投影层

2. **设计并实现训练流程**
   - 实现数据加载和批处理
   - 设计对比学习损失函数
   - 实现模型训练和验证
   - 添加早停和模型保存功能

## 2025-03-24

### 完成工作

1. **实现了增强版文本编码器**
   - 完成了基于预训练中文BERT模型的文本编码器实现
   - 添加了多种池化策略支持，包括cls、mean、max、attention和weighted
   - 实现了层权重学习机制，支持不同层表示的加权组合
   - 添加了特征投影层，支持灵活的输出维度配置
   - 实现了直接编码文本的便捷接口，支持单条和批量文本处理

2. **开发了全面的测试框架**
   - 实现了文本编码器的单元测试，验证了所有功能点
   - 开发了池化策略比较工具，分析了不同策略的性能差异
   - 添加了测试结果保存和可视化功能
   - 实现了自动化测试流程，确保代码质量

3. **进行了池化策略性能分析**
   - 比较了不同池化策略在5G核心网查询文本上的表现
   - 发现weighted策略相似度最高，但区分度不够
   - cls和attention策略在语义区分上表现较好
   - 分析了各策略的优缺点和适用场景
   - 为RAG系统提供了策略选择建议

4. **更新了相关文档**
   - 更新了项目进度报告，添加了文本编码器实现的内容
   - 更新了工作日志，记录了实现细节和测试结果
   - 调整了后续工作计划和时间线

### 讨论记录

1. **池化策略选择**
   - 讨论了不同池化策略的优缺点
   - 分析了在5G核心网资源查询场景下的适用性
   - 确认了检索阶段使用cls或attention策略更合适
   - 讨论了策略组合的可能性和实现方式

2. **文本编码器与图编码器的集成**
   - 讨论了如何确保文本和图特征的维度一致性
   - 分析了特征投影层的设计和参数选择
   - 确认了双通道编码器的接口兼容性
   - 讨论了训练过程中的特征对齐策略


## 2025-03-25

### 完成工作

1. **重构了数据集生成脚本**
   - 修改了`scripts/generate_dataset.py`脚本，移除了`node_ids`参数，改为使用`split_ratio`参数进行数据集划分
   - 优化了数据集生成流程，支持训练集、验证集和测试集的自动划分
   - 添加了更详细的日志记录，包括数据库连接时间、节点类型统计等信息
   - 移除了不再使用的`create_dataset_with_retry`函数，简化了代码结构
   - 实现了多线程数据处理，提高了数据集生成效率

2. **分析了特征提取和文本编码的实现**
   - 深入分析了`test_feature_extraction.py`脚本，理解了节点特征、边特征和链路特征的提取逻辑
   - 分析了`test_text_encoder.py`脚本，理解了文本编码器的基本功能、池化策略、投影层和层权重等实现
   - 确认了特征提取的范围包括节点基本属性、业务属性、性能指标和动态数据
   - 确认了文本编码支持多种池化策略，包括CLS池化、平均池化、最大池化、注意力池化和加权池化

3. **分析了模型架构与数据集的匹配性**
   - 分析了`rag/models`目录下的模型文件，包括`text_encoder.py`、`dynamic_heterogeneous_graph_encoder.py`、`dual_encoder.py`和`loss.py`
   - 确认了模型架构与当前数据集构建、特征提取和文本生成过程的匹配性
   - 验证了`TextEncoder`适合处理中文文本，支持多种池化策略和输出维度
   - 验证了`DynamicHeterogeneousGraphEncoder`适合处理动态异构图，匹配数据集的节点和边类型
   - 确认了`DualEncoder`有效集成了文本和图编码器，确保嵌入在相同语义空间对齐
   - 确认了损失函数如`ContrastiveLoss`适合文本-图匹配任务

4. **测试了数据集生成脚本**
   - 使用修改后的脚本成功生成了完整的训练、验证和测试数据集
   - 验证了数据集生成过程中的节点类型平衡、自适应子图大小、负样本生成和数据增强功能
   - 确认了生成的数据集符合模型训练的要求

### 讨论记录

1. **特征提取和文本编码的合理性**
   - 讨论了当前特征提取的范围是否全面，确认覆盖了节点、边和链路的关键特征
   - 分析了文本编码的多种策略，确认当前实现能够满足不同场景的需求
   - 讨论了特征和文本描述的匹配性，确认当前设计能够支持图-文对齐学习

2. **数据集生成的优化方向**
   - 讨论了数据集生成过程中的性能瓶颈，提出了多线程处理和批量操作的优化方案
   - 分析了数据集划分策略，确认当前的比例划分能够满足模型训练和评估的需求
   - 讨论了数据增强和负样本生成的策略，提出了进一步优化的方向

### 下一步计划

1. **开始模型训练**
   - 使用生成的数据集开始训练双通道编码器模型
   - 实验不同的损失函数组合和训练策略
   - 监控训练过程，分析模型性能

2. **实现检索评估**
   - 开发检索评估脚本，评估模型的检索性能
   - 实现多种评估指标，如Hits@K、MRR、NDCG等
   - 分析模型在不同查询类型上的表现

3. **开发索引系统**
   - 实现FAISS索引，支持高效的向量检索
   - 开发混合索引策略，结合语义检索和结构检索
   - 优化索引性能，支持大规模数据集

# 工作日志记录

## 2025-03-15

### 完成的工作
1. 初始化项目结构
2. 实现基础的特征提取器
3. 实现基本的双通道编码器架构
4. 设计并实现基础的对比损失函数

### 遇到的问题
1. 图结构数据的表示方式需要进一步优化
2. 文本编码器的池化策略需要进行比较实验

### 下一步计划
1. 完善特征提取器功能
2. 实现更多的池化策略
3. 设计并实现更多的损失函数

## 2025-03-16

### 完成的工作
1. 实现了多种文本池化策略（CLS、平均池化、最大池化、注意力池化）
2. 完成了文本编码器的测试脚本
3. 设计并实现了多种高级损失函数：
   - 批量对比损失（BatchContrastiveLoss）
   - 多正样本损失（MultiPositiveLoss）
   - 硬负样本挖掘损失（HardNegativeMiningLoss）
   - 组合损失（CombinedLoss）
4. 开发了损失函数测试脚本，验证了各种损失函数的实现
5. 开发了完整的训练脚本，支持配置加载、模型训练、评估和可视化
6. 重构了项目结构，将训练脚本移动到`rag/scripts`目录，将评估指标工具移动到`rag/utils`目录
7. 更新了`rag/training/trainer.py`以支持新的损失函数
8. 更新了项目文档，包括设计文档和目录结构说明

### 遇到的问题
1. 在测试损失函数时发现了一些边界情况的处理问题，特别是当某些权重为0时
2. 训练脚本与现有的训练器存在一些接口不一致的问题

### 解决方案
1. 修复了损失函数中的边界情况处理，确保当权重为0时不会返回对应的损失组件
2. 重构了训练脚本，使用现有的`Trainer`类，同时保留配置加载和可视化功能

### 下一步计划
1. 实现数据集的扩展和增强功能
2. 开始训练双通道编码器模型
3. 实现检索评估脚本，评估模型的检索性能
4. 开发索引构建和查询处理功能

## 损失函数测试结果分析

通过测试脚本对各种损失函数进行了测试，主要发现：

1. **基础对比损失函数**表现良好，能够完美区分正负样本对
2. **三元组损失**在测试数据上达到了理想状态，正样本距离远小于负样本距离
3. **批量对比损失**在使用硬负样本时损失值略有增加，但不影响准确率
4. **多正样本损失**和**硬负样本挖掘损失**在测试数据上表现不佳，可能需要调整参数或改进实现
5. **组合损失**在混合权重配置下表现最佳，说明结合不同类型的损失可能有协同效应

基于测试结果，我们决定在实际训练中优先使用**组合损失**，结合对比损失和三元组损失，以获得更好的训练效果。 